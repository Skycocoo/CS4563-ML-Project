{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder to predict the next tweet of Donald Trump\n",
    "\n",
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of data:  (30669,)\n",
      "1     Heading to California with @GOPLeader Kevin Mc...\n",
      "2     ....I can’t imagine any President having a bet...\n",
      "3     The New York Times did a phony story as usual ...\n",
      "4     Congratulations to Andrew Gillum on having run...\n",
      "5     I can get Nancy Pelosi as many votes as she wa...\n",
      "6     Thank you @JerryBrownGov. Look forward to join...\n",
      "7     ....their country’s flag. Can this be possible...\n",
      "8     Isn’t it ironic that large Caravans of people ...\n",
      "9     Congratulations to Brian Kemp on becoming the ...\n",
      "10    Congratulations to Ron DeSantis on becoming th...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "FILE = './allTweets.csv' #Index(['ource', 'text', 'created_at', 'id_str'\n",
    "data = pd.read_csv(FILE)['text']\n",
    "\n",
    "# we want to get the original tweets from trump, instead of retweets (RT) / responses (RE)\n",
    "remove = (data.str.contains(\"RT\", case=True, na=False) | data.str.contains(\"RE\", case=True, na=False))\n",
    "# ~: element-wise NOT operation\n",
    "data = data[~remove]\n",
    "\n",
    "print(\"total number of data: \", data.shape)\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-0766847d4756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# tokenizer = Tokenizer(MAX_NB_WORDS)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# import keras\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "# tokenizer = Tokenizer(MAX_NB_WORDS)\n",
    "# tokenizer.fit_on_texts(texts)\n",
    "# word_index = tokenizer.word_index #the dict values start from 1 so this is fine with zeropadding\n",
    "# index2word = {v: k for k, v in word_index.items()}\n",
    "# print('Found %s unique tokens' % len(word_index))\n",
    "# sequences = tokenizer.texts_to_sequences(texts)\n",
    "# data_1 = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "# print('Shape of data tensor:', data_1.shape)\n",
    "# NB_WORDS = (min(tokenizer.num_words, len(word_index)) + 1 ) #+1 for zero padding\n",
    "# data_1_val = data_1[801000:807000] #select 6000 sentences as validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
